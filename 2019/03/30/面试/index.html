<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>面试 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="1、面试1.1 数据仓库（数据挖掘，ETL）理论1.什么是数据仓库？数据仓库是面向主题的、集成的、时变的和非易失的有组织的数据集合，支持管理决策制定。 2.基本的数据模型，区别，适用场景ER模型、维度模型 3.数据仓库的基本架构数据源、ETL、数据仓库、元数据、OLAP 4.数据仓库分层架构，每层的作用数据缓冲层、数据明细层、数据模型层、数据集市层、数据应用层 5.实现数据增量抽取的方式（除了加时">
<meta name="keywords" content="面试">
<meta property="og:type" content="article">
<meta property="og:title" content="面试">
<meta property="og:url" content="http://yoursite.com/2019/03/30/面试/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1、面试1.1 数据仓库（数据挖掘，ETL）理论1.什么是数据仓库？数据仓库是面向主题的、集成的、时变的和非易失的有组织的数据集合，支持管理决策制定。 2.基本的数据模型，区别，适用场景ER模型、维度模型 3.数据仓库的基本架构数据源、ETL、数据仓库、元数据、OLAP 4.数据仓库分层架构，每层的作用数据缓冲层、数据明细层、数据模型层、数据集市层、数据应用层 5.实现数据增量抽取的方式（除了加时">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-03-30T09:33:43.661Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="面试">
<meta name="twitter:description" content="1、面试1.1 数据仓库（数据挖掘，ETL）理论1.什么是数据仓库？数据仓库是面向主题的、集成的、时变的和非易失的有组织的数据集合，支持管理决策制定。 2.基本的数据模型，区别，适用场景ER模型、维度模型 3.数据仓库的基本架构数据源、ETL、数据仓库、元数据、OLAP 4.数据仓库分层架构，每层的作用数据缓冲层、数据明细层、数据模型层、数据集市层、数据应用层 5.实现数据增量抽取的方式（除了加时">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-面试" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/03/30/面试/" class="article-date">
  <time datetime="2019-03-30T09:19:54.000Z" itemprop="datePublished">2019-03-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      面试
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="1、面试"><a href="#1、面试" class="headerlink" title="1、面试"></a>1、面试</h2><h3 id="1-1-数据仓库（数据挖掘，ETL）理论"><a href="#1-1-数据仓库（数据挖掘，ETL）理论" class="headerlink" title="1.1 数据仓库（数据挖掘，ETL）理论"></a>1.1 数据仓库（数据挖掘，ETL）理论</h3><h5 id="1-什么是数据仓库？"><a href="#1-什么是数据仓库？" class="headerlink" title="1.什么是数据仓库？"></a>1.什么是数据仓库？</h5><p>数据仓库是面向主题的、集成的、时变的和非易失的有组织的数据集合，支持管理决策制定。</p>
<h5 id="2-基本的数据模型，区别，适用场景"><a href="#2-基本的数据模型，区别，适用场景" class="headerlink" title="2.基本的数据模型，区别，适用场景"></a>2.基本的数据模型，区别，适用场景</h5><p>ER模型、维度模型</p>
<h5 id="3-数据仓库的基本架构"><a href="#3-数据仓库的基本架构" class="headerlink" title="3.数据仓库的基本架构"></a>3.数据仓库的基本架构</h5><p>数据源、ETL、数据仓库、元数据、OLAP</p>
<h5 id="4-数据仓库分层架构，每层的作用"><a href="#4-数据仓库分层架构，每层的作用" class="headerlink" title="4.数据仓库分层架构，每层的作用"></a>4.数据仓库分层架构，每层的作用</h5><p>数据缓冲层、数据明细层、数据模型层、数据集市层、数据应用层</p>
<h5 id="5-实现数据增量抽取的方式（除了加时间戳外，其它方式）"><a href="#5-实现数据增量抽取的方式（除了加时间戳外，其它方式）" class="headerlink" title="5.实现数据增量抽取的方式（除了加时间戳外，其它方式）"></a>5.实现数据增量抽取的方式（除了加时间戳外，其它方式）</h5><p>1、时间戳<br>2、md5(col_all)</p>
<h5 id="6-用过的ETL工具及报表工具，及特点"><a href="#6-用过的ETL工具及报表工具，及特点" class="headerlink" title="6.用过的ETL工具及报表工具，及特点"></a>6.用过的ETL工具及报表工具，及特点</h5><p>1、kettle<br>2、impala</p>
<h5 id="7-雪花模型和星型模型的区别"><a href="#7-雪花模型和星型模型的区别" class="headerlink" title="7.雪花模型和星型模型的区别"></a>7.雪花模型和星型模型的区别</h5><p>一个是数据冗余度的区别，星型模型的数据冗余度比雪花型要高，另一个是查询的性能问题，星型模型的使用便捷性和查询性能要高于雪花型</p>
<h5 id="8-OLAP和OLTP的区别"><a href="#8-OLAP和OLTP的区别" class="headerlink" title="8.OLAP和OLTP的区别"></a>8.OLAP和OLTP的区别</h5><p>OLAP联机分析处理，OLTP联机事务处理</p>
<h5 id="9-缓慢变化维度如何处理"><a href="#9-缓慢变化维度如何处理" class="headerlink" title="9.缓慢变化维度如何处理"></a>9.缓慢变化维度如何处理</h5><h5 id="10-项目中最重要或最需要注意的部分，如何处理？"><a href="#10-项目中最重要或最需要注意的部分，如何处理？" class="headerlink" title="10.项目中最重要或最需要注意的部分，如何处理？"></a>10.项目中最重要或最需要注意的部分，如何处理？</h5><h5 id="11-元数据管理哪些方面？"><a href="#11-元数据管理哪些方面？" class="headerlink" title="11.元数据管理哪些方面？"></a>11.元数据管理哪些方面？</h5><h5 id="12-数据抽取注意事项，如何保证？"><a href="#12-数据抽取注意事项，如何保证？" class="headerlink" title="12.数据抽取注意事项，如何保证？"></a>12.数据抽取注意事项，如何保证？</h5><h5 id="13-拉链表的优缺点"><a href="#13-拉链表的优缺点" class="headerlink" title="13.拉链表的优缺点"></a>13.拉链表的优缺点</h5><h5 id="14-数据质量管控如何实现？"><a href="#14-数据质量管控如何实现？" class="headerlink" title="14.数据质量管控如何实现？"></a>14.数据质量管控如何实现？</h5><h5 id="15-事实维度表的类型有哪些"><a href="#15-事实维度表的类型有哪些" class="headerlink" title="15.事实维度表的类型有哪些"></a>15.事实维度表的类型有哪些</h5><h5 id="16-对于数据的注意事项"><a href="#16-对于数据的注意事项" class="headerlink" title="16.对于数据的注意事项"></a>16.对于数据的注意事项</h5><h5 id="17-数据库三范式"><a href="#17-数据库三范式" class="headerlink" title="17.数据库三范式"></a>17.数据库三范式</h5><h3 id="1-2-Hadoop原理及操作"><a href="#1-2-Hadoop原理及操作" class="headerlink" title="1.2 Hadoop原理及操作"></a>1.2 Hadoop原理及操作</h3><h4 id="1-2-1-集群"><a href="#1-2-1-集群" class="headerlink" title="1.2.1 集群"></a>1.2.1 集群</h4><h5 id="1-用过的集群及规模"><a href="#1-用过的集群及规模" class="headerlink" title="1.用过的集群及规模"></a>1.用过的集群及规模</h5><p>2+15，2T+200T，2.6.5<br>2+4，1T+100T，2.6.5<br>2+35，4T+1225T，2.6.0-cdh5.13.3</p>
<h5 id="2-每个组件的基本作用"><a href="#2-每个组件的基本作用" class="headerlink" title="2.每个组件的基本作用"></a>2.每个组件的基本作用</h5><p>基本模块：<br> Hadoop 基础功能库：支持其他 Hadoop 模块的通用程序包。<br> HDFS ：一个分布式文件系统，能够以高吞吐量访问应用的数据。<br> YARN ：一个作业调度和资源管理框架。<br> MapReduce ：一个基于 YARN 的大数据并行处理程序。<br>其他模块：<br> HBase ：一个可扩展的分布式数据库，支持大表的结构化数据存储。<br> Hive ：一个数据仓库基础架构，提供数据汇总和命令行的即席查询功能。<br> Spark ：一个处理 Hadoop 数据的、高速的、通用的计算引擎。<br> ZooKeeper ：一个用于分布式应用的高性能协调服务。</p>
<h5 id="3-基本的命令"><a href="#3-基本的命令" class="headerlink" title="3.基本的命令"></a>3.基本的命令</h5><p>参考<a href="https://app.yinxiang.com/shard/s59/nl/20503510/3ab45895-d8c6-4df5-a055-9e213b1a980f" target="_blank" rel="noopener">Hadoop集群基本命令</a></p>
<h4 id="1-2-2-MapReduce"><a href="#1-2-2-MapReduce" class="headerlink" title="1.2.2 MapReduce"></a>1.2.2 MapReduce</h4><h5 id="1-MapReduce工作原理"><a href="#1-MapReduce工作原理" class="headerlink" title="1.MapReduce工作原理"></a>1.MapReduce工作原理</h5><h5 id="2-Hadoop提交任务的流程"><a href="#2-Hadoop提交任务的流程" class="headerlink" title="2.Hadoop提交任务的流程"></a>2.Hadoop提交任务的流程</h5><h5 id="3-MR图的绘制"><a href="#3-MR图的绘制" class="headerlink" title="3.MR图的绘制"></a>3.MR图的绘制</h5><h5 id="4-MR的二次排序"><a href="#4-MR的二次排序" class="headerlink" title="4.MR的二次排序"></a>4.MR的二次排序</h5><h5 id="5-YARN的原理，MR原理一样么？"><a href="#5-YARN的原理，MR原理一样么？" class="headerlink" title="5.YARN的原理，MR原理一样么？"></a>5.YARN的原理，MR原理一样么？</h5><p>以上五个参考Hadoop系列-Hadoop知识点 笔记</p>
<h4 id="6-MapReduce的map数和reduce数控制"><a href="#6-MapReduce的map数和reduce数控制" class="headerlink" title="6.MapReduce的map数和reduce数控制"></a>6.MapReduce的map数和reduce数控制</h4><h4 id="1-2-3-Hive"><a href="#1-2-3-Hive" class="headerlink" title="1.2.3 Hive"></a>1.2.3 Hive</h4><h5 id="1-Hive-SQL具体的函数使用"><a href="#1-Hive-SQL具体的函数使用" class="headerlink" title="1.Hive SQL具体的函数使用"></a>1.Hive SQL具体的函数使用</h5><p>参考<a href="https://app.yinxiang.com/shard/s59/nl/20503510/191059da-ab15-4bed-b0c1-26576fbd56ca" target="_blank" rel="noopener">Hive常用函数</a></p>
<h5 id="2-全局排序和分组排序的区别（Sort-By，Order-By，Cluster-By，Distrbute-By）"><a href="#2-全局排序和分组排序的区别（Sort-By，Order-By，Cluster-By，Distrbute-By）" class="headerlink" title="2.全局排序和分组排序的区别（Sort By，Order By，Cluster By，Distrbute By）"></a>2.全局排序和分组排序的区别（Sort By，Order By，Cluster By，Distrbute By）</h5><p>order by：会对输入做全局排序，因此只有一个reducer（多个reducer无法保证全局有序）。只有一个reducer，会导致当输入规模较大时，需要较长的计算时间<br>sort by：不是全局排序，其在数据进入reducer前完成排序。<br>distribute by：按照指定的字段对数据进行划分输出到不同的reduce中。<br>cluster by：除了具有 distribute by 的功能外还兼具 sort by 的功能</p>
<h5 id="3-UDF编写，关键是自己的处理具体问题的想法"><a href="#3-UDF编写，关键是自己的处理具体问题的想法" class="headerlink" title="3.UDF编写，关键是自己的处理具体问题的想法"></a>3.UDF编写，关键是自己的处理具体问题的想法</h5><h5 id="4-hql的行转列，列转行"><a href="#4-hql的行转列，列转行" class="headerlink" title="4.hql的行转列，列转行"></a>4.hql的行转列，列转行</h5><p>实现hive里横转纵的功能<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select gmsfhm,  gddh1   from zb_dwa.DWA_R_JB_RYDHHMK t lateral view explode(split(t.gddh,&apos;,&apos;))a as gddh1 where gmsfhm=&apos;152301198209100568&apos;;</span><br><span class="line">152632196712060315    ,13088573907,13034744906    </span><br><span class="line">转化成                   </span><br><span class="line">152632196712060315    13088573907</span><br><span class="line">152632196712060315    13034744906</span><br></pre></td></tr></table></figure></p>
<p>实现hive里纵变横的功能<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">原始:</span><br><span class="line">sys_region (id,name)</span><br><span class="line">1 a</span><br><span class="line">1 b</span><br><span class="line">2 c</span><br><span class="line">2 d</span><br><span class="line">select id,concat_ws(&apos;,&apos;,collect_set(name))</span><br><span class="line">from sys_region</span><br><span class="line">group by id;</span><br><span class="line">结果:</span><br><span class="line">1 a,b</span><br><span class="line">2 c,d</span><br></pre></td></tr></table></figure></p>
<h5 id="5-Hive里的UDF有哪几种"><a href="#5-Hive里的UDF有哪几种" class="headerlink" title="5.Hive里的UDF有哪几种"></a>5.Hive里的UDF有哪几种</h5><p>用户自定义函数：UDF<br>用户自定义聚合函数：UDAF<br>用户自定义表生成函数：UDTF</p>
<h5 id="6-count-distinct-xxx-如何优化"><a href="#6-count-distinct-xxx-如何优化" class="headerlink" title="6.count(distinct xxx)如何优化"></a>6.count(distinct xxx)如何优化</h5><p>select count (1) from (select distinct xxx from b) a;</p>
<h5 id="7-数据倾斜会出现在什么情况下，如何处理"><a href="#7-数据倾斜会出现在什么情况下，如何处理" class="headerlink" title="7.数据倾斜会出现在什么情况下，如何处理"></a>7.数据倾斜会出现在什么情况下，如何处理</h5><p>发生场景：<br>1.有聚合运算的时候<br>2.有join的时候<br>处理方案：<br>第一种方案：建临时表<br>第二种方案：将key通过随机数打散后运算，然后再重新拆分聚合<br>第三种方案：设置参数 set hive.exec.reducers.bytes.per.reducer以及set hive.optimize.skewjoin = true<br>第四种方案：大小表关联用map join，group by的时候设置参数</p>
<h5 id="8-Hive几种join方式"><a href="#8-Hive几种join方式" class="headerlink" title="8.Hive几种join方式"></a>8.Hive几种join方式</h5><p>inner join，只有进行连接的两个表中都存在与连接标准相匹配的数据才会保留下来。<br>left join，join操作符左边表中符合where子句的所有记录将会被返回。<br>right join，会返回右边表中所有符合where语句的记录<br>full join，会返回所有表中符合where语句条件的所有记录<br>笛卡尔积join，表示左边表的行数乘以右边表的行数等于笛卡尔结果集的大小。</p>
<h5 id="9-Hive有哪几种文件存储格式，大概说一下原理"><a href="#9-Hive有哪几种文件存储格式，大概说一下原理" class="headerlink" title="9.Hive有哪几种文件存储格式，大概说一下原理"></a>9.Hive有哪几种文件存储格式，大概说一下原理</h5><p>1.TEXTFILE为默认的存储格式，行式存储。如果建表的时候不特殊指定则采用这种格式存储，便于和其他工具（grep，sed和awk等）共享数据，也便于查看和编辑。但是相对于二进制文件，存储空间要大。<br>2.SequenceFile文件存储格式，行式存储。定义表结构时可以通过STORED AS SEQUENCEFILE语句指定。SequenceFile文件是含有键-值对的二进制文件，是Hadoop本身就可以支持的一种标准文件格式。SequenceFile可以在块级别和记录级别进行压缩，同时仍然可以支持按照块级别的文件分割，以方便并行处理。<br>3.RCfile文件存储格式，是一种行列存储相结合的存储方式。首先，其将数据按行分块，保证同一个记录在一个块上，避免读一个记录需要读取多个block。其次，块数据列式存储，有利于数据压缩和快速的列存取。<br>主要用到这三种。</p>
<h5 id="10-Hive实现拉链表"><a href="#10-Hive实现拉链表" class="headerlink" title="10.Hive实现拉链表"></a>10.Hive实现拉链表</h5><h5 id="11-条件写在join后面和写在where后面的区别"><a href="#11-条件写在join后面和写在where后面的区别" class="headerlink" title="11.条件写在join后面和写在where后面的区别"></a>11.条件写在join后面和写在where后面的区别</h5><p>join是数据在查询范围内用join   where 只获得符合条件的数据<br>对结果集：join不符合的显示的是null  where 是不显示的</p>
<h5 id="12-Hive的压缩格式及区别"><a href="#12-Hive的压缩格式及区别" class="headerlink" title="12.Hive的压缩格式及区别"></a>12.Hive的压缩格式及区别</h5><p>使用压缩的优势是可以最小化所需要的磁盘存储空间，以及减小磁盘和网络I/O操作。但是，文件压缩过程和解压过程会增加CPU开销。<br>BZip2压缩率最高，但是同时需要消耗最多的COU开销。<br>GZIP是压缩率和压缩/解压缩速度上的下一个选择。<br>LZO和Snappy压缩率相比前面的2种要小但是压缩/解压缩速度要快。<br>GZIP和Snappy压缩的文件不可分割。</p>
<h5 id="13-row-number和rank有啥区别"><a href="#13-row-number和rank有啥区别" class="headerlink" title="13.row_number和rank有啥区别"></a>13.row_number和rank有啥区别</h5><ul>
<li>row_number()从1开始，按照顺序，生成分组内记录的序列,row_number()的值不会存在重复,当排序的值相同时,按照表中记录的顺序进行排列</li>
<li>RANK() 生成数据项在分组中的排名，排名相等会在名次中留下空位</li>
<li>DENSE_RANK() 生成数据项在分组中的排名，排名相等会在名次中不会留下空位<h5 id="14-Hive分区，分桶表"><a href="#14-Hive分区，分桶表" class="headerlink" title="14.Hive分区，分桶表"></a>14.Hive分区，分桶表</h5>Hive分区是指按照数据表的某列或某些列分为多个区，分区从形式上可以理解为文件夹。<br>分桶是相对分区进行更细粒度的划分，分桶将整个数据内容安装某列属性值得hash值进行区分。<h5 id="15-常用优化方式"><a href="#15-常用优化方式" class="headerlink" title="15.常用优化方式"></a>15.常用优化方式</h5>1.使用EXPLAIN查看执行计划。<br>2.JOIN优化。1）将最大的表放置在JOIN语句的最右边。2）使用map-side JOIN。<br>3.开启本地模式。<br>4.开启并行执行。<br>5.开启严格模式。<br>6.调整mapper和reducer个数。<br>7.JVM重用。<br>8.开启压缩。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">一些调优参数</span><br><span class="line">set hive.groupby.skewindata=true;                                                                       //当数据出现倾斜时，会自动进行负载均衡</span><br><span class="line">set hive.exec.compress.output=true;                                                                     //hive最终输出是否压缩</span><br><span class="line">set mapred.output.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;     //map的输出压缩方式</span><br><span class="line">set mapred.output.compression.type=BLOCK;                                                         //压缩类型，默认为RECORD，压缩单独的记录，BLOCK为块压缩</span><br><span class="line">set mapreduce.map.memory.mb=2049;                                                                 //每个map的内存大小</span><br><span class="line">set mapreduce.reduce.memory.mb=2049;                                                              //每个reduce的内存大小</span><br><span class="line">set hive.exec.parallel=true;                                                                                 //控制同一个sql中的不同的job是否可以同时运行，默认为false</span><br><span class="line">set hive.exec.parallel.thread.number=4;                                                                  //控制对于同一个sql来说同时可以运行的job的最大值，默认为8</span><br><span class="line">set mapred.max.split.size=256000000;                                                                   //决定每个map处理的最大的文件大小，单位为B</span><br><span class="line">set mapred.min.split.size.per.node=100000000;                                                       //节点中可以处理的最小的文件的大小</span><br><span class="line">set mapred.min.split.size.per.rack=100000000;                                                        //机架中可以处理的最小的文件的大小</span><br><span class="line">set hive.merge.mapfiles=true;                                                                             //在Map-only的任务结束时合并小文件</span><br><span class="line">set hive.merge.mapredfiles=true;                                                                         //在Map-Reduce的任务结束时合并小文件</span><br><span class="line">set hive.merge.size.per.task=128000000;                                                                //合并文件的大小</span><br><span class="line">set hive.meger.smallfiles.avgsize=100000000;                                                          //当输出文件的平均大小小于该值时，启动一个独立的map-reduce任务进行文件合并</span><br><span class="line">set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat;                //hive的输入 InputFormat</span><br><span class="line">set hive.hadoop.supports.splittable.combineinputformat=true;                                    //是否支持可切分的combineinputformat</span><br><span class="line">set mapred.reduce.tasks=10;</span><br><span class="line">set hive.exec.reducers.bytes.per.reducer=750000000;                                                 //控制reducer个数</span><br><span class="line">set hive.exec.compress.output=true;                                                                      //hive最终输出是否压缩</span><br><span class="line">set mapred.compress.map.output=false;                                                                 //hadoop参数，map输出是否压缩</span><br><span class="line">set mapred.output.compress=true;                                                                        //hadoop参数，reduce输出是否压缩</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h5 id="16-exist怎么实现比较快"><a href="#16-exist怎么实现比较快" class="headerlink" title="16.exist怎么实现比较快"></a>16.exist怎么实现比较快</h5><h5 id="17-left-semi-join什么特点"><a href="#17-left-semi-join什么特点" class="headerlink" title="17.left semi join什么特点"></a>17.left semi join什么特点</h5><h5 id="18-不用order-by-实现全局排序"><a href="#18-不用order-by-实现全局排序" class="headerlink" title="18.不用order by 实现全局排序"></a>18.不用order by 实现全局排序</h5><h5 id="19-不用开窗函数-实现分组-topN"><a href="#19-不用开窗函数-实现分组-topN" class="headerlink" title="19.不用开窗函数 实现分组 topN"></a>19.不用开窗函数 实现分组 topN</h5><h5 id="20-SQL怎么解决数据倾斜（不用map-side-join）"><a href="#20-SQL怎么解决数据倾斜（不用map-side-join）" class="headerlink" title="20.SQL怎么解决数据倾斜（不用map side join）"></a>20.SQL怎么解决数据倾斜（不用map side join）</h5><h4 id="1-2-4-Spark"><a href="#1-2-4-Spark" class="headerlink" title="1.2.4 Spark"></a>1.2.4 Spark</h4><h5 id="1-Spark-2-0新特性"><a href="#1-Spark-2-0新特性" class="headerlink" title="1.Spark 2.0新特性"></a>1.Spark 2.0新特性</h5><h4 id="1-2-5-HBase"><a href="#1-2-5-HBase" class="headerlink" title="1.2.5 HBase"></a>1.2.5 HBase</h4><h5 id="1-HBase工作原理"><a href="#1-HBase工作原理" class="headerlink" title="1.HBase工作原理"></a>1.HBase工作原理</h5><h5 id="2-rowkey设计原理"><a href="#2-rowkey设计原理" class="headerlink" title="2.rowkey设计原理"></a>2.rowkey设计原理</h5><h5 id="3-HBase分区"><a href="#3-HBase分区" class="headerlink" title="3.HBase分区"></a>3.HBase分区</h5><h5 id="4-HBase和Hadoop有什么区别，脱离HDFS能存在么？"><a href="#4-HBase和Hadoop有什么区别，脱离HDFS能存在么？" class="headerlink" title="4.HBase和Hadoop有什么区别，脱离HDFS能存在么？"></a>4.HBase和Hadoop有什么区别，脱离HDFS能存在么？</h5><h4 id="1-2-6-Kafka"><a href="#1-2-6-Kafka" class="headerlink" title="1.2.6 Kafka"></a>1.2.6 Kafka</h4><h5 id="1-Kafka接数的原理"><a href="#1-Kafka接数的原理" class="headerlink" title="1.Kafka接数的原理"></a>1.Kafka接数的原理</h5><h4 id="1-2-7-ZooKeeper"><a href="#1-2-7-ZooKeeper" class="headerlink" title="1.2.7 ZooKeeper"></a>1.2.7 ZooKeeper</h4><h3 id="1-3-常用SQL"><a href="#1-3-常用SQL" class="headerlink" title="1.3 常用SQL"></a>1.3 常用SQL</h3><h4 id="1-3-1-基于Hive的SQL及常用优化"><a href="#1-3-1-基于Hive的SQL及常用优化" class="headerlink" title="1.3.1 基于Hive的SQL及常用优化"></a>1.3.1 基于Hive的SQL及常用优化</h4><h5 id="1-求连续五天通过一个卡口的车辆"><a href="#1-求连续五天通过一个卡口的车辆" class="headerlink" title="1.求连续五天通过一个卡口的车辆"></a>1.求连续五天通过一个卡口的车辆</h5><h5 id="2-求一段数字排列中不连续的排列"><a href="#2-求一段数字排列中不连续的排列" class="headerlink" title="2.求一段数字排列中不连续的排列"></a>2.求一段数字排列中不连续的排列</h5><h5 id="3-求一个学生的成绩占总成绩的百分比"><a href="#3-求一个学生的成绩占总成绩的百分比" class="headerlink" title="3.求一个学生的成绩占总成绩的百分比"></a>3.求一个学生的成绩占总成绩的百分比</h5><p>思路：通过表自关联实现</p>
<h5 id="4-字段a，b，c，值为1000，2000，中国；3000，4000，美国，给定1500，求中国"><a href="#4-字段a，b，c，值为1000，2000，中国；3000，4000，美国，给定1500，求中国" class="headerlink" title="4.字段a，b，c，值为1000，2000，中国；3000，4000，美国，给定1500，求中国"></a>4.字段a，b，c，值为1000，2000，中国；3000，4000，美国，给定1500，求中国</h5><p>思路：（写udf实现，使用luce索引）java<br>1）写sql<br>2）自选方案</p>
<h5 id="5-分组求top-N"><a href="#5-分组求top-N" class="headerlink" title="5.分组求top N"></a>5.分组求top N</h5><h5 id="6-行转列，列转行具体写法"><a href="#6-行转列，列转行具体写法" class="headerlink" title="6.行转列，列转行具体写法"></a>6.行转列，列转行具体写法</h5><h4 id="1-3-2-基于Mysql的SQL优化"><a href="#1-3-2-基于Mysql的SQL优化" class="headerlink" title="1.3.2 基于Mysql的SQL优化"></a>1.3.2 基于Mysql的SQL优化</h4><h4 id="1-3-3-基于Oracle的SQL优化"><a href="#1-3-3-基于Oracle的SQL优化" class="headerlink" title="1.3.3 基于Oracle的SQL优化"></a>1.3.3 基于Oracle的SQL优化</h4><h3 id="1-4-Linux-Shell"><a href="#1-4-Linux-Shell" class="headerlink" title="1.4 Linux Shell"></a>1.4 Linux Shell</h3><h4 id="1-4-1-常用命令"><a href="#1-4-1-常用命令" class="headerlink" title="1.4.1 常用命令"></a>1.4.1 常用命令</h4><h3 id="1-5-编程语言"><a href="#1-5-编程语言" class="headerlink" title="1.5 编程语言"></a>1.5 编程语言</h3><h3 id="1-6-项目经验"><a href="#1-6-项目经验" class="headerlink" title="1.6 项目经验"></a>1.6 项目经验</h3>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/03/30/面试/" data-id="cjv0wvnc30007igxi5jengdcl" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/面试/">面试</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2019/03/31/ARTS第二周/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          ARTS第二周
        
      </div>
    </a>
  
  
    <a href="/2019/03/24/ARTS第一周/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">ARTS第一周</div>
    </a>
  
</nav>

  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/ARTS/">ARTS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/面试/">面试</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/ARTS/" style="font-size: 20px;">ARTS</a> <a href="/tags/面试/" style="font-size: 10px;">面试</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/04/">April 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/03/">March 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/04/28/ARTS第五周/">ARTS第五周</a>
          </li>
        
          <li>
            <a href="/2019/04/14/ARTS第四周/">ARTS第四周</a>
          </li>
        
          <li>
            <a href="/2019/04/07/ARTS第三周/">ARTS第三周</a>
          </li>
        
          <li>
            <a href="/2019/04/05/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2019/03/31/ARTS第二周/">ARTS第二周</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 John Doe<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>